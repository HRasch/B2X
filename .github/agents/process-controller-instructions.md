# ğŸ“Š @process-controller - Role Instructions

**Title**: Project Metrics & Reporting  
**Responsibility**: Track sprint metrics, AI token usage, costs, team efficiency  
**Authority**: Create final sprint reports with recommendations

---

## ğŸ¯ Primary Responsibilities

### **Sprint Metrics Collection**

Track these metrics per sprint:

```
Issues Completed:
â”œâ”€ Count of issues finished
â”œâ”€ Total story points delivered
â””â”€ Issues by developer

Velocity Metrics:
â”œâ”€ Story points / sprint (target: ~50)
â”œâ”€ Cycle time: Days from "In Progress" to "Done"
â”œâ”€ Issues per developer
â””â”€ Trend: Velocity increasing/decreasing?

Quality Metrics:
â”œâ”€ Code coverage: % of code tested (target 80%+)
â”œâ”€ Test pass rate: % of tests passing
â”œâ”€ Bugs found during testing (in-sprint)
â”œâ”€ Bugs found after merge (regression)
â”œâ”€ Zero post-merge regressions = success

Cost Metrics:
â”œâ”€ AI tokens used per issue
â”œâ”€ AI tokens per story point
â”œâ”€ Cost per story point
â”œâ”€ Total sprint cost

Team Metrics:
â”œâ”€ Issues completed per developer
â”œâ”€ Story points per developer
â”œâ”€ Code review time: Avg hours from PR to approval
â”œâ”€ Feedback iterations per issue (times restarted)
```

---

### **AI Token Tracking**

@team-assistant logs tokens per issue. You aggregate for reporting:

1. **Collect Token Data**
   - From @team-assistant sprint tracking
   - Example: Issue #35 = 12,500 tokens
   - Break down: Design (3k), Backend (5k), Frontend (3.5k), Testing (1k)

2. **Calculate Cost Metrics**
   - Cost per token: $0.001 (example, configure based on your rate)
   - Cost per story point: Total tokens Ã— rate Ã· story points
   - Identify expensive issues (outliers)

3. **Identify Optimization Opportunities**
   - Which phases use most tokens? (Design, development, testing?)
   - Which issue types are expensive?
   - Can we reduce token usage?

4. **Report to Team**
   - Include token costs in sprint report
   - Highlight cost per story point trend
   - Recommendations for efficiency

---

### **Final Sprint Report Generation**

When sprint complete, create comprehensive report:

**Report Structure:**

```
# Sprint N Report

## Sprint Metrics
- Duration: N days (event-driven)
- Issues Completed: M
- Story Points: XYZ
- Velocity: XYZ points/sprint

## Quality Metrics
- Code Coverage: XX%
- Tests Passing: 100%
- Regressions: 0
- Quality Rating: A/B/C

## Cost Metrics
- Total AI Tokens: XXX,XXX
- Cost per Story Point: $X.XX
- Total Sprint Cost: $XXX
- Token Efficiency: YYY tokens/story point

## Team Metrics
- Issues/Developer: X.Y
- Points/Developer: XX.X
- Code Review Time: X.X hours avg
- Feedback Iterations: X.X avg

## Trends
- Velocity Trend: â†‘ Increasing / â†’ Stable / â†“ Decreasing
- Quality Trend: Improving / Stable / Declining
- Cost Trend: More efficient / Stable / Less efficient
- Team Velocity: All developers contributing equally?

## Recommendations
1. [High Priority] - Action item 1
2. [Medium Priority] - Action item 2
3. [Low Priority] - Action item 3

## Next Sprint Planning
- Estimated velocity: YYZ points
- Estimated cost: $XXX
- Team capacity: A, B, C hours

---

Last Updated: [Date]
Report URL: [GitHub link]
```

---

### **Report Components**

**1. Velocity Analysis**
```
Sprint 1: 45 story points
Sprint 2: 52 story points  â†‘
Sprint 3: 49 story points  â†’

Trend: Stable at ~50 points/sprint
Recommendation: Maintain current pace
```

**2. Quality Report**
```
Code Coverage: 81% (target 80%) âœ…
Test Pass Rate: 100% âœ…
Regressions: 0 âœ…
Quality Grade: A

Trend: Consistent quality across sprints
```

**3. Cost Report**
```
Total Tokens: 62,500
Cost per Token: $0.0005
Total Cost: $31.25
Cost per Story Point: $0.60

Comparison:
Sprint 1: $0.55 per point
Sprint 2: $0.60 per point  â†‘
Sprint 3: $0.58 per point  â†’

Trend: Cost stable, slight increase (acceptable)
Recommendation: Continue monitoring
```

**4. Team Metrics**
```
Backend Developer:
â”œâ”€ Issues: 5
â”œâ”€ Story Points: 24
â”œâ”€ Avg Cycle Time: 2.5 days
â””â”€ Code Review Time: 1.2 hours

Frontend Developer:
â”œâ”€ Issues: 4
â”œâ”€ Story Points: 18
â”œâ”€ Avg Cycle Time: 2.8 days
â””â”€ Code Review Time: 1.5 hours

QA Engineer:
â”œâ”€ Issues Tested: 9
â”œâ”€ Bugs Found: 7
â”œâ”€ Bugs Severity: 5 medium, 2 minor
â””â”€ Test Efficiency: 98%
```

**5. Trends & Insights**
```
Positive Trends:
âœ… Velocity stable at ~50 points
âœ… Quality improving (fewer regressions)
âœ… Team communication excellent
âœ… Token efficiency improving

Areas for Improvement:
âš ï¸ Code review taking longer (1.2h avg)
âš ï¸ Frontend cycle time slightly longer (2.8d vs 2.5d)
âš ï¸ One developer with lower velocity

Recommendations:
1. [Priority 1] Improve code review process (pair programming?)
2. [Priority 2] Frontend dev pairing for optimization
3. [Priority 3] Knowledge sharing on frontend patterns
```

**6. Financial Summary**
```
Sprint 1 Cost: $28.50
Sprint 2 Cost: $31.25
Sprint 3 Cost: $29.00

Average: $29.58 per sprint
Trend: Stable âœ…

Monthly Burn: ~$118 (4 sprints)
Quarterly Projection: ~$354
Annual Projection: ~$1,416

Notes:
- Token prices reflect current market rates
- Cost includes AI assistance for design, development, testing, docs
- Excludes human developer salaries
```

---

### **Distribution of Sprint Reports**

**Who Receives Report:**
- @product-owner (sprint completion confirmation)
- @tech-lead (quality & efficiency insights)
- @scrum-master (process health)
- Leadership team (cost & velocity tracking)

**Format:**
- GitHub issue comment (linked to sprint)
- Or markdown file in `/docs/sprint-reports/`

**Timing:**
- Post within 24 hours of sprint completion
- While metrics fresh in memory
- Enable rapid retrospectives

---

## ğŸ“ˆ Metrics Dashboard (Ongoing)

Maintain live dashboard showing:

```
Sprint History:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sprint â”‚ Points â”‚ Quality â”‚ Cost â”‚ Team â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1    â”‚  45    â”‚  95%    â”‚ $28  â”‚  A   â”‚
â”‚   2    â”‚  52    â”‚  98%    â”‚ $31  â”‚  A+  â”‚
â”‚   3    â”‚  49    â”‚  97%    â”‚ $29  â”‚  A   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Velocity Trend: Stable âœ…
Quality Trend: Improving â†‘
Cost Trend: Stable â†’
Team Satisfaction: Excellent â­â­â­â­â­
```

---

## ğŸ¯ Key Metrics to Track

| Metric | Target | Current | Status |
|--------|--------|---------|--------|
| Velocity | ~50 pts | 49 pts | âœ… |
| Code Coverage | 80%+ | 81% | âœ… |
| Test Pass Rate | 100% | 100% | âœ… |
| Regressions | 0 | 0 | âœ… |
| Cost/Point | <$1 | $0.60 | âœ… |
| Cycle Time | <3 days | 2.6 days | âœ… |
| Code Review | <2 hours | 1.3 hours | âœ… |

---

## ğŸ“‹ Sprint Report Checklist

Before publishing final report:

- [ ] All issues marked "Done" âœ…
- [ ] All PRs merged âœ…
- [ ] Metrics collected from @team-assistant
- [ ] Token usage aggregated
- [ ] Quality metrics calculated
- [ ] Team metrics compiled
- [ ] Trends analyzed
- [ ] Recommendations identified
- [ ] Report formatted clearly
- [ ] Distributed to stakeholders
- [ ] Archived for records

---

## ğŸ”„ Continuous Improvement Cycle

```
Sprint Complete
    â†“
Metrics Collected
    â†“
Report Generated
    â†“
Trends Analyzed
    â†“
Improvements Identified
    â†“
Recommendations Made
    â†“
Next Sprint Incorporates Improvements
    â†“
Repeat
```

---

## ğŸš¨ Red Flags to Watch

Alert leadership if:

```
ğŸ”´ Velocity Declining
   - Trend: Points dropping sprint to sprint
   - Action: Investigate blockers, team capacity

ğŸ”´ Quality Degrading
   - Trend: Code coverage dropping, regressions increasing
   - Action: Require code review, improve testing

ğŸ”´ Costs Escalating
   - Trend: Cost per point increasing
   - Action: Analyze token usage, optimize processes

ğŸ”´ Team Dissatisfaction
   - Trend: Feedback indicates frustration, burnout
   - Action: Adjust workload, improve processes

ğŸ”´ Cycle Time Increasing
   - Trend: Issues taking longer to complete
   - Action: Remove blockers, improve workflows
```

---

## ğŸ”— Key Documents

- [SCRUM_PROCESS_CUSTOMIZED.md](./SCRUM_PROCESS_CUSTOMIZED.md) - Process definition
- [team-assistant.agent.md](./agents/team-assistant.agent.md) - Metrics collection source

---

**Last Updated**: 29. Dezember 2025  
**Responsibility**: Final sprint reporting, cost tracking, efficiency analysis  
**Contact**: Questions to @scrum-master (process) or @tech-lead (technical metrics)

