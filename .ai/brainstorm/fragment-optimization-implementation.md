# Fragment Optimization Extensions - Implementation Plan

**Date**: 2026-01-08  
**Based on**: Successful 99% markdown token savings via DocumentationMCP integration  
**Focus**: High-impact extensions with clear implementation paths

---

## ðŸŽ¯ Phase 1: Multi-Format Documentation (1-2 weeks)

### Target: JSON, YAML, XML Configuration Files

**Why Priority**: Immediate 90-95% savings on large config files (appsettings.json, package.json, OpenAPI specs)

### Implementation Plan

#### 1.1 Add JSON Fragment Extraction to DocumentationMCP

**File**: `tools/DocumentationMCP/src/index.ts`

```typescript
{
  name: 'extract_json_fragment',
  description: 'Extract intelligent fragments from large JSON files for token-efficient editing',
  inputSchema: {
    type: 'object',
    properties: {
      filePath: { type: 'string', description: 'Path to JSON file' },
      workspacePath: { type: 'string', description: 'Workspace root directory' },
      maxKeys: { type: 'number', default: 50, minimum: 20, maximum: 200 },
      preserveStructure: { type: 'boolean', default: true },
      includeComments: { type: 'boolean', default: false },
      sampleArrays: { type: 'boolean', default: true }
    },
    required: ['filePath', 'workspacePath']
  }
}
```

**Algorithm**:
1. Parse JSON structure
2. Extract top-level keys (preserve structure)
3. Sample array elements (first N + last N)
4. Include nested object outlines
5. Report token savings

#### 1.2 Add YAML Fragment Extraction

**Similar to JSON but handle YAML-specific features**:
- Frontmatter-style headers
- Multi-document YAML streams
- Comments preservation
- Anchor/alias handling

#### 1.3 Add XML Fragment Extraction

**XML-specific considerations**:
- Preserve tag structure
- Extract attributes selectively
- Handle namespaces
- Sample repetitive elements

### Expected Results
- **appsettings.json**: 500+ lines â†’ 50-100 lines (90% savings)
- **package.json**: Complex dependency trees â†’ essential config only
- **OpenAPI specs**: 2000+ lines â†’ core endpoints + schemas

---

## ðŸŽ¯ Phase 2: Code Fragmentation Foundation (2-3 weeks)

### Target: Large service classes and utility files

**Why Priority**: 80-90% savings on focused code editing, addresses pain point of large monolithic files

### Implementation Approach

#### 2.1 Extend Roslyn MCP Server

**File**: `tools/RoslynMCP/src/index.ts` (assuming similar structure)

```typescript
{
  name: 'extract_code_fragment',
  description: 'Extract focused code fragments for efficient editing',
  inputSchema: {
    type: 'object',
    properties: {
      filePath: { type: 'string', description: 'Path to code file' },
      workspacePath: { type: 'string', description: 'Workspace root directory' },
      targetSymbol: { type: 'string', description: 'Method/class name to focus on' },
      contextLines: { type: 'number', default: 10, minimum: 5, maximum: 50 },
      includeDependencies: { type: 'boolean', default: true },
      includeImports: { type: 'boolean', default: true }
    },
    required: ['filePath', 'workspacePath']
  }
}
```

**Algorithm**:
1. Parse C# code with Roslyn
2. Find target symbol (method/class)
3. Extract symbol definition + context lines
4. Include relevant using statements
5. Add dependent symbols if requested
6. Generate focused fragment

#### 2.2 Integration with Existing Roslyn MCP

**Leverage existing tools**:
- `roslyn-mcp/analyze_types` for symbol analysis
- `roslyn-mcp/check_breaking_changes` for dependency validation
- `roslyn-mcp/invoke_refactoring` for code cleanup

### Expected Results
- **Service classes**: 1000+ LOC â†’ 100-200 LOC focused method
- **Test files**: Multiple test cases â†’ single test context
- **Utility libraries**: Many functions â†’ targeted function + dependencies

---

## ðŸŽ¯ Phase 3: Configuration Profiles System (1 week)

### Target: Standardized extraction strategies

**Why Priority**: Ensures consistency and optimizes for specific use cases

### Implementation Plan

#### 3.1 Profile Configuration System

**File**: `tools/DocumentationMCP/src/profiles.ts`

```typescript
export const FRAGMENT_PROFILES = {
  'documentation-review': {
    includeHeaders: true,
    includeFrontmatter: true,
    sampleContent: true,
    maxLines: 100
  },
  'code-editing': {
    includeImports: true,
    includeDependencies: true,
    methodContext: 5,
    maxLines: 150
  },
  'config-validation': {
    preserveStructure: true,
    includeComments: false,
    maxKeys: 50
  },
  'api-review': {
    includeEndpoints: true,
    includeSchemas: true,
    sampleResponses: true,
    maxLines: 80
  }
};
```

#### 3.2 Profile-Aware MCP Tools

**Enhanced tool signatures**:
```typescript
extract_markdown_fragment(filePath, workspacePath, profile?: 'documentation-review')
extract_json_fragment(filePath, workspacePath, profile?: 'config-validation')
extract_code_fragment(filePath, workspacePath, profile?: 'code-editing')
```

### Benefits
- **Consistency**: Same extraction behavior for similar tasks
- **Optimization**: Profiles tuned for specific workflows
- **User Experience**: Simple profile selection vs complex parameters

---

## ðŸ”§ Technical Architecture

### Shared Fragment Engine

**File**: `tools/DocumentationMCP/src/fragment-engine.ts`

```typescript
export class FragmentEngine {
  static async extractFragment(
    filePath: string,
    options: FragmentOptions,
    analyzer: FileAnalyzer
  ): Promise<FragmentResult> {
    const content = await this.readFile(filePath);
    const analysis = await analyzer.analyze(content);
    const fragment = await this.buildFragment(content, analysis, options);

    return {
      originalLines: content.split('\n').length,
      fragmentLines: fragment.split('\n').length,
      tokenSavings: this.calculateSavings(content, fragment),
      content: fragment
    };
  }
}
```

### File-Specific Analyzers

**Interface**: `FileAnalyzer`
- `MarkdownAnalyzer` for markdown files
- `JsonAnalyzer` for JSON files
- `CodeAnalyzer` for source code
- `XmlAnalyzer` for XML files

### Quality Assurance

**Automated validation**:
- Fragment completeness checks
- Context preservation verification
- Token savings calculation
- Performance benchmarking

---

## ðŸ“Š Success Metrics & Validation

### Quantitative Metrics
- **Token Savings**: Target 80-99% across all file types
- **Processing Time**: <2 seconds for files up to 500KB
- **Fragment Quality**: >95% essential information preserved
- **Error Rate**: <1% fragment-related failures

### Qualitative Metrics
- **Developer Feedback**: Fragment usefulness for editing tasks
- **Adoption Rate**: % of AI sessions using fragment extraction
- **Workflow Integration**: Seamless integration with existing tools

### Validation Approach
1. **Unit Tests**: Fragment extraction algorithms
2. **Integration Tests**: MCP tool functionality
3. **Performance Tests**: Benchmarking against full file processing
4. **User Acceptance**: Real-world editing scenarios

---

## ðŸš€ Implementation Timeline

### Week 1: Foundation
- [ ] Multi-format documentation fragmentation (JSON, YAML)
- [ ] Configuration profiles system
- [ ] Enhanced error handling and validation
- [ ] Unit tests for new functionality

### Week 2: Code Intelligence
- [ ] Code fragmentation foundation (Roslyn MCP integration)
- [ ] Dependency analysis and import optimization
- [ ] Language-specific extraction strategies
- [ ] Integration testing

### Week 3-4: Advanced Features
- [ ] Semantic content analysis (optional AI enhancement)
- [ ] Performance monitoring and analytics
- [ ] Documentation updates and user guides
- [ ] Production deployment and monitoring

---

## ðŸŽ¯ Risk Mitigation

### Technical Risks
1. **Performance Degradation**: Implement performance budgets and monitoring
2. **Fragment Quality Issues**: Automated quality checks and user feedback loops
3. **Integration Complexity**: Incremental rollout with feature flags

### Operational Risks
1. **Adoption Resistance**: Provide clear benefits and training
2. **Maintenance Overhead**: Automated testing and monitoring
3. **Breaking Changes**: Version compatibility and migration paths

### Mitigation Strategies
- **Fallback Options**: Always provide full file access
- **Gradual Rollout**: Feature flags for controlled deployment
- **Monitoring**: Comprehensive logging and alerting
- **User Support**: Documentation and troubleshooting guides

---

## ðŸ“ˆ Expected ROI

### Immediate Benefits (Phase 1)
- **90-95% token savings** on configuration files
- **Faster AI responses** for documentation tasks
- **Reduced context window usage** in editing sessions

### Medium-term Benefits (Phase 2)
- **80-90% token savings** on code editing
- **Improved developer productivity** for large file modifications
- **Enhanced AI workflow integration** across languages

### Long-term Benefits (Phase 3)
- **Consistent optimization** across all file types
- **Adaptive intelligence** from usage patterns
- **Continuous improvement** through quality metrics

---

**Implementation Lead**: @SARAH (coordination)  
**Technical Leads**: @Backend (Roslyn), @Frontend (TypeScript), @Architect (system design)  
**Timeline**: 4 weeks to initial deployment  
**Success Criteria**: 80%+ token savings across supported file types</content>
<parameter name="filePath">c:\Users\Holge\repos\B2Connect\.ai\brainstorm\fragment-optimization-implementation.md